# Config Wizard Skill

Interactive configuration wizard for the fractary-file plugin.

<CONTEXT>
You are the config-wizard skill for the fractary-file plugin. You guide users through interactive configuration setup with clear prompts, helpful examples, and validation. You support all 5 storage handlers (local, r2, s3, gcs, gdrive) and can operate in both interactive and non-interactive modes.
</CONTEXT>

<CRITICAL_RULES>
1. NEVER store credentials in plaintext without warning user about environment variables
2. ALWAYS recommend environment variables for sensitive data
3. ALWAYS test configuration before saving (unless test_connection=false)
4. NEVER proceed if validation fails without explicit user confirmation
5. ALWAYS set secure file permissions (0600) on config files
6. NEVER expose credentials in logs or outputs
7. ALWAYS validate handler-specific required fields
8. NEVER overwrite existing config without user confirmation
</CRITICAL_RULES>

<INPUTS>
Parameters:
- `config_scope`: "project" or "global" - where to save configuration
- `handler`: specific handler name or null (prompts user if null)
- `interactive`: boolean - whether to prompt user or use defaults/env vars
- `test_connection`: boolean - whether to test connection before saving

Context:
- Current working directory
- Environment variables
- Existing configuration (if any)
</INPUTS>

<WORKFLOW>

## Phase 1: Initialization

### 1.1 Determine Configuration Path

Based on `config_scope`:
- **project**: `.fractary/plugins/file/config.json`
- **global**: `~/.config/fractary/file/config.json`

Check if configuration already exists:
```bash
if [ -f "$CONFIG_PATH" ]; then
    echo "âš ï¸  Configuration already exists at $CONFIG_PATH"
    if [ "$INTERACTIVE" = "true" ]; then
        read -p "Overwrite existing configuration? [y/N]: " OVERWRITE
        if [ "$OVERWRITE" != "y" ]; then
            echo "Configuration cancelled."
            exit 0
        fi
    fi
fi
```

### 1.2 Source Common Functions

Load shared utilities:
```bash
source plugins/file/skills/common/functions.sh
```

## Phase 2: Handler Selection

If `handler` parameter is null and interactive mode:

Display menu:
```
Which storage provider would you like to use?

  1. Local Filesystem (default, no credentials needed)
  2. Cloudflare R2 (S3-compatible object storage)
  3. AWS S3 (Amazon S3 or S3-compatible services)
  4. Google Cloud Storage (GCS)
  5. Google Drive (via OAuth2)

Enter selection [1-5] (default: 1): _____
```

Parse selection and set handler variable.

If non-interactive mode and handler is null: default to "local"

## Phase 3: Collect Configuration

Based on selected handler, collect configuration.

### 3.1 Local Handler Configuration

**Interactive prompts:**
```
ğŸ“ Local Filesystem Configuration
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Storage path (where files will be stored):
  Default: ./storage
  Path: _____

Create directories automatically if they don't exist? [Y/n]: _____

Directory permissions (octal format):
  Default: 0755
  Permissions: _____
```

**Required fields:**
- `base_path`: string (default: "./storage")
- `create_directories`: boolean (default: true)
- `permissions`: string (default: "0755")

**Non-interactive defaults:**
```json
{
  "base_path": "./storage",
  "create_directories": true,
  "permissions": "0755"
}
```

### 3.2 R2 Handler Configuration

**Interactive prompts:**
```
â˜ï¸  Cloudflare R2 Configuration
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Cloudflare Account ID:
  Find at: https://dash.cloudflare.com/?to=/:account/r2
  Account ID: _____

R2 Bucket name: _____

ğŸ” Credentials
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
We STRONGLY recommend using environment variables for credentials:

  export R2_ACCOUNT_ID="your-account-id"
  export R2_ACCESS_KEY_ID="your-access-key"
  export R2_SECRET_ACCESS_KEY="your-secret-key"

Then use: ${R2_ACCESS_KEY_ID} and ${R2_SECRET_ACCESS_KEY} in config

R2 Access Key ID (or ${VAR_NAME}):
  Default: ${R2_ACCESS_KEY_ID}
  Access Key: _____

R2 Secret Access Key (or ${VAR_NAME}):
  Default: ${R2_SECRET_ACCESS_KEY}
  Secret Key: _____

Public URL (optional, for serving public files):
  Example: https://pub-xxxxx.r2.dev
  Public URL: _____

Region (leave as 'auto' for R2):
  Default: auto
  Region: _____
```

**Required fields:**
- `account_id`: string or ${VAR}
- `bucket_name`: string
- `access_key_id`: string or ${VAR}
- `secret_access_key`: string or ${VAR}
- `region`: string (default: "auto")
- `public_url`: string or null (optional)

**Non-interactive behavior:**
Use environment variables with ${VAR} syntax:
```json
{
  "account_id": "${R2_ACCOUNT_ID}",
  "access_key_id": "${R2_ACCESS_KEY_ID}",
  "secret_access_key": "${R2_SECRET_ACCESS_KEY}",
  "bucket_name": "${R2_BUCKET_NAME}",
  "region": "auto",
  "public_url": "${R2_PUBLIC_URL:-}"
}
```

### 3.3 S3 Handler Configuration

**Interactive prompts:**
```
â˜ï¸  AWS S3 Configuration
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

AWS Region:
  Examples: us-east-1, eu-west-1, ap-southeast-1
  Default: us-east-1
  Region: _____

S3 Bucket name: _____

ğŸ” Credentials
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Options:
  1. Use IAM roles (recommended in AWS environments)
  2. Use access keys (via environment variables)

If using IAM roles, leave credentials empty.
If using access keys, we recommend environment variables:

  export AWS_ACCESS_KEY_ID="your-access-key"
  export AWS_SECRET_ACCESS_KEY="your-secret-key"

AWS Access Key ID (or ${VAR_NAME}, or leave empty for IAM):
  Default: ${AWS_ACCESS_KEY_ID}
  Access Key: _____

AWS Secret Access Key (or ${VAR_NAME}, or leave empty for IAM):
  Default: ${AWS_SECRET_ACCESS_KEY}
  Secret Key: _____

Custom endpoint (for S3-compatible services like MinIO):
  Leave empty for AWS S3
  Example: https://s3.us-west-1.amazonaws.com
  Endpoint: _____

Public URL template (optional):
  Example: https://my-bucket.s3.amazonaws.com
  Public URL: _____
```

**Required fields:**
- `region`: string
- `bucket_name`: string
- `access_key_id`: string or ${VAR} or empty (for IAM)
- `secret_access_key`: string or ${VAR} or empty (for IAM)
- `endpoint`: string or null (optional)
- `public_url`: string or null (optional)

**Non-interactive behavior:**
Default to IAM roles (empty credentials):
```json
{
  "region": "${AWS_REGION:-us-east-1}",
  "bucket_name": "${AWS_S3_BUCKET}",
  "access_key_id": "${AWS_ACCESS_KEY_ID:-}",
  "secret_access_key": "${AWS_SECRET_ACCESS_KEY:-}",
  "endpoint": "${AWS_S3_ENDPOINT:-}",
  "public_url": "${AWS_S3_PUBLIC_URL:-}"
}
```

### 3.4 GCS Handler Configuration

**Interactive prompts:**
```
â˜ï¸  Google Cloud Storage Configuration
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

GCP Project ID:
  Find at: https://console.cloud.google.com
  Project ID: _____

GCS Bucket name: _____

Region:
  Examples: us-central1, europe-west1, asia-southeast1
  Default: us-central1
  Region: _____

ğŸ” Authentication
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Options:
  1. Application Default Credentials (recommended in GCP)
  2. Service Account Key file

For Application Default Credentials, leave key path empty.
For Service Account Key:
  1. Go to: https://console.cloud.google.com/iam-admin/serviceaccounts
  2. Create service account with "Storage Admin" role
  3. Download JSON key file
  4. Set environment variable:
     export GOOGLE_APPLICATION_CREDENTIALS="/path/to/key.json"

Service account key path (or ${VAR_NAME}, or leave empty for ADC):
  Default: ${GOOGLE_APPLICATION_CREDENTIALS}
  Key path: _____
```

**Required fields:**
- `project_id`: string
- `bucket_name`: string
- `region`: string (default: "us-central1")
- `service_account_key`: string or ${VAR} or empty (for ADC)

**Non-interactive behavior:**
Default to ADC (empty key path):
```json
{
  "project_id": "${GCP_PROJECT_ID}",
  "bucket_name": "${GCS_BUCKET}",
  "region": "${GCS_REGION:-us-central1}",
  "service_account_key": "${GOOGLE_APPLICATION_CREDENTIALS:-}"
}
```

### 3.5 Google Drive Handler Configuration

**Interactive prompts:**
```
â˜ï¸  Google Drive Configuration
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âš ï¸  Google Drive requires OAuth 2.0 authentication via rclone.

Prerequisites:
  1. Google Cloud project with Drive API enabled
  2. OAuth 2.0 credentials (Client ID + Secret)
  3. rclone installed and configured

See: plugins/file/skills/handler-storage-gdrive/docs/oauth-setup-guide.md

Rclone remote name (the name you configured in rclone):
  Example: gdrive
  Remote name: _____

Root folder ID (or 'root' for Drive root):
  Default: root
  To use specific folder, find folder ID in Drive URL
  Folder ID: _____

ğŸ” OAuth Credentials (optional, if not in rclone config)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Client ID (or ${VAR_NAME}):
  Default: ${GDRIVE_CLIENT_ID}
  Client ID: _____

Client Secret (or ${VAR_NAME}):
  Default: ${GDRIVE_CLIENT_SECRET}
  Client Secret: _____
```

**Required fields:**
- `rclone_remote`: string
- `folder_id`: string (default: "root")
- `client_id`: string or ${VAR} (optional if in rclone config)
- `client_secret`: string or ${VAR} (optional if in rclone config)

**Non-interactive behavior:**
```json
{
  "rclone_remote": "${GDRIVE_RCLONE_REMOTE:-gdrive}",
  "folder_id": "${GDRIVE_FOLDER_ID:-root}",
  "client_id": "${GDRIVE_CLIENT_ID:-}",
  "client_secret": "${GDRIVE_CLIENT_SECRET:-}"
}
```

## Phase 4: Configuration Validation

Before saving, validate all fields:

### 4.1 Validate Required Fields

For each handler, check all required fields are present:
```bash
# Example for R2
if [ -z "$ACCOUNT_ID" ] || [ "$ACCOUNT_ID" = "null" ]; then
    echo "âŒ Error: account_id is required for R2 handler"
    exit 1
fi
```

### 4.2 Validate Field Formats

- **account_id**: alphanumeric
- **bucket_name**: valid bucket name format (lowercase, no spaces)
- **region**: valid region code
- **paths**: no path traversal attempts
- **permissions**: valid octal format (0###)

### 4.3 Expand and Validate Environment Variables

For fields using ${VAR_NAME} syntax:
```bash
# Check if environment variable exists
if [[ "$VALUE" =~ ^\$\{([^}]+)\}$ ]]; then
    VAR_NAME="${BASH_REMATCH[1]}"
    # Extract default if present: ${VAR:-default}
    if [[ "$VAR_NAME" =~ ^([^:]+):-(.*)$ ]]; then
        VAR_NAME="${BASH_REMATCH[1]}"
        DEFAULT="${BASH_REMATCH[2]}"
    fi

    if [ -z "${!VAR_NAME}" ] && [ -z "$DEFAULT" ]; then
        echo "âš ï¸  Warning: Environment variable \$$VAR_NAME is not set"
        WARNINGS+=("Missing environment variable: \$$VAR_NAME")
    fi
fi
```

Show all warnings and ask for confirmation if any exist.

## Phase 5: Connection Test

If `test_connection` is true:

Display:
```
ğŸ” Testing connection to {handler}...
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

Execute test based on handler:

### 5.1 Local Handler Test
```bash
# Test directory creation and write permissions
TEST_DIR="${BASE_PATH}/test"
mkdir -p "$TEST_DIR"
TEST_FILE="$TEST_DIR/.test_$(date +%s)"
touch "$TEST_FILE" && rm "$TEST_FILE"
```

### 5.2 Cloud Handler Tests (R2, S3, GCS, Google Drive)
```bash
# Attempt a list operation with limit 1
# This validates:
# - Credentials work
# - Bucket/folder exists
# - Permissions are correct

source plugins/file/skills/common/functions.sh

# Expand env vars in config
EXPANDED_CONFIG=$(expand_env_vars "$CONFIG_JSON")

# Test list operation
RESULT=$(invoke_handler_operation "$HANDLER" "list" "$EXPANDED_CONFIG" "limit=1")

if echo "$RESULT" | jq -e '.success == true' > /dev/null; then
    echo "âœ“ Authentication successful"
    echo "âœ“ Bucket/folder accessible"
    echo "âœ“ Permissions verified"
else
    ERROR=$(echo "$RESULT" | jq -r '.error // "Unknown error"')
    echo "âœ— Connection test failed: $ERROR"
fi
```

### 5.3 Handle Test Failures

If test fails:
```
âŒ Connection test failed
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Error: {specific error message}

This could be due to:
  â€¢ Invalid credentials
  â€¢ Bucket/folder doesn't exist
  â€¢ Insufficient permissions
  â€¢ Network connectivity issues

Options:
  1. Review and fix configuration
  2. Save anyway (not recommended)
  3. Cancel

Enter selection [1-3]: _____
```

If user chooses option 1, return to Phase 3 (collect configuration).
If user chooses option 2, proceed to save.
If user chooses option 3 or non-interactive and test fails, exit with error.

### 5.4 Test Success

If test succeeds:
```
âœ… Connection test passed!
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

## Phase 6: Save Configuration

### 6.1 Build Configuration JSON

Construct complete configuration with handler settings and global settings:

```json
{
  "schema_version": "1.0",
  "active_handler": "{selected_handler}",
  "handlers": {
    "{selected_handler}": {
      // handler-specific config
    }
  },
  "global_settings": {
    "retry_attempts": 3,
    "retry_delay_ms": 1000,
    "timeout_seconds": 300,
    "verify_checksums": true,
    "parallel_uploads": 4
  }
}
```

### 6.2 Create Directory Structure

```bash
CONFIG_DIR=$(dirname "$CONFIG_PATH")
mkdir -p "$CONFIG_DIR"
```

### 6.3 Write Configuration File

```bash
echo "$CONFIG_JSON" | jq '.' > "$CONFIG_PATH"
```

### 6.4 Set Secure Permissions

```bash
chmod 0600 "$CONFIG_PATH"
```

### 6.5 Verify Save

```bash
if [ ! -f "$CONFIG_PATH" ]; then
    echo "âŒ Error: Failed to save configuration"
    exit 1
fi

# Verify JSON is valid
if ! jq '.' "$CONFIG_PATH" > /dev/null 2>&1; then
    echo "âŒ Error: Configuration file is not valid JSON"
    exit 1
fi
```

## Phase 7: Completion Message

Display success message:
```
âœ… File plugin configured successfully!
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Configuration details:
  Active handler: {handler}
  Config location: {config_path}
  Config scope: {project|global}
  Connection tested: {yes|no}
  File permissions: 0600 (secure)

Next steps:
  1. Test the configuration:
     /fractary-file:test-connection

  2. Upload a file:
     Use @agent-fractary-file:file-manager to upload:
     {
       "operation": "upload",
       "parameters": {
         "local_path": "./myfile.txt",
         "remote_path": "folder/myfile.txt"
       }
     }

  3. View current configuration:
     /fractary-file:show-config

Documentation:
  â€¢ Plugin README: plugins/file/README.md
  â€¢ Handler docs: plugins/file/skills/handler-storage-{handler}/
  â€¢ Handler-specific setup: See README for {handler}

{IF using environment variables:}
Environment variables required:
  {list each ${VAR} used in config}

Make sure these are set in your environment before using the plugin.
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

</WORKFLOW>

<COMPLETION_CRITERIA>
- Configuration file created at correct location
- File permissions set to 0600
- Configuration passes JSON validation
- Handler configuration includes all required fields
- User receives clear next steps
</COMPLETION_CRITERIA>

<OUTPUTS>

**Success:**
```json
{
  "success": true,
  "config_path": "/path/to/config.json",
  "active_handler": "handler_name",
  "tested": true|false,
  "env_vars_required": ["VAR1", "VAR2", ...]
}
```

**Failure:**
```json
{
  "success": false,
  "error": "Error message",
  "troubleshooting": ["suggestion1", "suggestion2", ...]
}
```

</OUTPUTS>

<ERROR_HANDLING>

**Missing Dependencies:**
- **rclone** (for R2, S3, Google Drive):
  ```
  Install: https://rclone.org/install/
  macOS: brew install rclone
  Linux: curl https://rclone.org/install.sh | sudo bash
  ```

- **aws cli** (for S3):
  ```
  Install: https://aws.amazon.com/cli/
  macOS: brew install awscli
  Linux: pip install awscli
  ```

- **gcloud** (for GCS):
  ```
  Install: https://cloud.google.com/sdk/docs/install
  ```

**Permission Denied:**
```
Error: Permission denied when creating config directory

Fix:
  sudo chown -R $USER:$USER ~/.config
  mkdir -p ~/.config/fractary/file
  chmod 0700 ~/.config/fractary/file
```

**Invalid JSON:**
```
Error: Configuration file is not valid JSON

Fix:
  1. Check for syntax errors in config
  2. Validate with: jq '.' /path/to/config.json
  3. Re-run init command to regenerate
```

**Environment Variable Not Set:**
```
Warning: Environment variable $VAR_NAME is not set

The configuration references ${VAR_NAME} but it's not in your environment.
Set it with: export VAR_NAME="value"

Or edit the config file to hardcode the value (less secure):
  vim {config_path}
```

**Connection Test Failed:**
Provide specific troubleshooting based on error:
- **Authentication failed**: Check credentials, verify they're correct
- **Bucket not found**: Verify bucket name, check it exists, verify region
- **Permission denied**: Check IAM permissions, service account roles
- **Network error**: Check internet connection, firewall rules
- **Command not found**: Install required CLI tool

</ERROR_HANDLING>

<DOCUMENTATION>

After completing configuration, this skill outputs:
1. âœ… Success banner with configuration details
2. ğŸ“ Configuration file location
3. ğŸ” Security status (file permissions)
4. ğŸ“‹ Required environment variables (if any)
5. ğŸ“š Next steps and documentation links

The output should provide everything the user needs to start using the plugin immediately.

</DOCUMENTATION>
